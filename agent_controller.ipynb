{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Optimal\n",
    "\n",
    "import copy\n",
    "import tempfile\n",
    "\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tensordict import TensorDictBase, TensorDict\n",
    "\n",
    "from tensordict.nn import TensorDictModule, TensorDictSequential\n",
    "from torch import multiprocessing, nn\n",
    "\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data import BoundedTensorSpec, CompositeSpec, UnboundedContinuousTensorSpec\n",
    "\n",
    "from torchrl.envs import (\n",
    "    CatTensors,\n",
    "    EnvBase,\n",
    "    Transform,\n",
    "    TransformedEnv,\n",
    "    UnsqueezeTransform,\n",
    "    ExplorationType,\n",
    "    RewardSum,\n",
    "    set_exploration_type,\n",
    ")\n",
    "\n",
    "from torchrl.modules import (\n",
    "    AdditiveGaussianWrapper,\n",
    "    MultiAgentMLP,\n",
    "    ProbabilisticActor,\n",
    "    TanhDelta,\n",
    ")\n",
    "\n",
    "from torchrl.envs.transforms.transforms import _apply_to_composite\n",
    "from torchrl.envs.utils import check_env_specs, step_mdp\n",
    "\n",
    "from torchrl.objectives import DDPGLoss, SoftUpdate, ValueEstimators\n",
    "\n",
    "from torchrl.record import CSVLogger, VideoRecorder\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Devices\n",
    "is_fork = multiprocessing.get_start_method() == \"fork\"\n",
    "device = (\n",
    "    torch.device(0)\n",
    "    if torch.cuda.is_available() and not is_fork\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "\n",
    "# Sampling\n",
    "frames_per_batch = 1_000  # Number of team frames collected per sampling iteration\n",
    "n_iters = 10  # Number of sampling and training iterations\n",
    "total_frames = frames_per_batch * n_iters\n",
    "\n",
    "# Replay buffer\n",
    "memory_size = 1_000_000  # The replay buffer of each group can store this many frames\n",
    "\n",
    "# Training\n",
    "n_optimizer_steps = 100  # Number of optimization steps per training iteration\n",
    "train_batch_size = 128  # Number of frames trained in each optimizer step\n",
    "lr = 3e-4  # Learning rate\n",
    "max_grad_norm = 1.0  # Maximum norm for the gradients\n",
    "\n",
    "# DDPG\n",
    "gamma = 0.99  # Discount factor\n",
    "polyak_tau = 0.005  # Tau for the soft-update of the target network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
